{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8178c540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent\t\t    configurator.py  logs.py\t  processing\tspinner.py\r\n",
      "app.py\t\t    __init__.py      __main__.py  prompts\turl_utils\r\n",
      "auto_gpt_workspace  js\t\t     main.py\t  __pycache__\tutils.py\r\n",
      "cli.py\t\t    json_utils\t     memory\t  setup.py\tworkspace\r\n",
      "commands\t    llm\t\t     models\t  singleton.py\r\n",
      "config\t\t    log_cycle\t     plugins.py   speech\r\n"
     ]
    }
   ],
   "source": [
    "!ls autogpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24857397",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m     block[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSPEAK\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mINFO SPEAK: (.*)\u001b[39m\u001b[38;5;124m'\u001b[39m, line)\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEBUG\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m line:\n\u001b[0;32m---> 18\u001b[0m     block[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mACTION\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDEBUG  (.*)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     19\u001b[0m     output\u001b[38;5;241m.\u001b[39mappend(block)\n\u001b[1;32m     20\u001b[0m     block \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPLAN\u001b[39m\u001b[38;5;124m\"\u001b[39m: []}\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "workflows = []\n",
    "block = {\"PLAN\": []}\n",
    "with open('logs/activity.log','r') as lines:\n",
    "    for line in lines:\n",
    "        if \"INFO PANGUGPT THOUGHTS:\" in line:\n",
    "            block[\"PANGUGPT THOUGHTS\"] = re.search(r'INFO PANGUGPT THOUGHTS: (.*)', line).group(1)\n",
    "        elif \"INFO REASONING:\" in line:\n",
    "            block[\"REASONING\"] = re.search(r'INFO REASONING: (.*)', line).group(1)\n",
    "        elif \"INFO -\" in line:\n",
    "            block[\"PLAN\"].append(re.search(r'INFO -  (.*)', line).group(1))\n",
    "        elif \"INFO SPEAK:\" in line:\n",
    "            block[\"SPEAK\"] = re.search(r'INFO SPEAK: (.*)', line).group(1)\n",
    "        elif \"DEBUG\" in line:\n",
    "            block[\"ACTION\"] = json.loads(re.search(r'DEBUG  (.*)', line).group(1))\n",
    "            output.append(block)\n",
    "            block = {\"PLAN\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1905b5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_by_action_lines = []\n",
    "one_action_resource = {'ACTION':[],'RESULT':None}\n",
    "with open('logs/activity.log','r') as lines:\n",
    "    for line in lines:\n",
    "        if \"NEXT ACTION:\" not in line:\n",
    "            one_action_resource['ACTION'].append(line)\n",
    "        else:\n",
    "            one_action_resource['RESULT']=re.search(r'NEXT ACTION: (.*)', line).group(1)\n",
    "            one_action_resource['ACTION']=parse_one_action(one_action_resource['ACTION'])\n",
    "            split_by_action_lines.append(one_action_resource)\n",
    "            one_action_resource = {'ACTION':[],'RESULT':None}\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e3f38ea6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " COMMAND = google  ARGUMENTS = {'query': 'Pangu Large Model'}\n",
      " COMMAND = browse_website  ARGUMENTS = {'url': 'https://www.huawei.com/en/press-events/news/2021/7/huawei-releases-pangu-large-model', 'question': 'What is the Pangu Large Model?'}\n",
      " COMMAND = google  ARGUMENTS = {'query': 'Pangu Large Model function and author'}\n",
      " COMMAND = google  ARGUMENTS = {'query': 'Pangu Large Model function and author'}\n",
      " COMMAND = read_file  ARGUMENTS = {'filename': '/home/zhangtianning/Documents/projects/Auto-GPT/autogpt/auto_gpt_workspace/pangu_large_model.txt'}\n",
      " COMMAND = write_to_file  ARGUMENTS = {'filename': '/home/zhangtianning/Documents/projects/Auto-GPT/autogpt/auto_gpt_workspace/pangu_large_model.txt', 'text': ''}\n",
      " COMMAND = google  ARGUMENTS = {'query': 'Pangu Large Model function and author'}\n",
      " COMMAND = google  ARGUMENTS = {'query': 'Pangu Large Model capabilities and applications'}\n",
      " COMMAND = read_file  ARGUMENTS = {'filename': '/home/zhangtianning/Documents/projects/Auto-GPT/autogpt/auto_gpt_workspace/pangu_large_model.txt'}\n",
      " COMMAND = google  ARGUMENTS = {'query': 'Pangu Large Model author'}\n",
      " COMMAND = browse_website  ARGUMENTS = {'url': 'https://www.linkedin.com/', 'question': 'Pangu Large Model authors'}\n",
      " COMMAND = google  ARGUMENTS = {'query': 'Pangu Large Model authors LinkedIn'}\n",
      " COMMAND = browse_website  ARGUMENTS = {'url': 'https://www.linkedin.com/in/hao-tian-7a5a5a1b/', 'question': 'What is the professional background and expertise of Dr. Hao Tian?'}\n",
      " COMMAND = google  ARGUMENTS = {'query': 'authors of the Pangu Large Model'}\n",
      " COMMAND = read_file  ARGUMENTS = {'filename': '/home/zhangtianning/Documents/projects/Auto-GPT/autogpt/auto_gpt_workspace/arxiv_paper.txt'}\n",
      " COMMAND = google  ARGUMENTS = {'query': 'Pangu Large Model authors'}\n",
      " COMMAND = google  ARGUMENTS = {'query': 'Pangu Large Model capabilities'}\n",
      " COMMAND = read_file  ARGUMENTS = {'filename': '/home/zhangtianning/Documents/projects/Auto-GPT/autogpt/auto_gpt_workspace/arxiv_paper.txt'}\n",
      " COMMAND = list_files  ARGUMENTS = {'directory': '/home/zhangtianning/Documents/projects/Auto-GPT/autogpt/auto_gpt_workspace'}\n",
      " COMMAND = google  ARGUMENTS = {'query': 'Pangu Large Model capabilities'}\n",
      " COMMAND = read_file  ARGUMENTS = {'filename': '/home/zhangtianning/Documents/projects/Auto-GPT/autogpt/auto_gpt_workspace/pangu_info.txt', 'text': 'In conclusion, the PanGu large-scale AI model presents a promising opportunity for Swiss engineers and organizations to capitalize on the latest advancements in artificial intelligence.'}\n",
      " COMMAND = write_to_file  ARGUMENTS = {'filename': '/home/zhangtianning/Documents/projects/Auto-GPT/autogpt/auto_gpt_workspace/pangu_info.txt', 'text': 'In conclusion, the PanGu large-scale AI model presents a promising opportunity for Swiss engineers and organizations to capitalize on the latest advancements in artificial intelligence.'}\n",
      " COMMAND = list_files  ARGUMENTS = {'directory': '/home/zhangtianning/Documents/projects/Auto-GPT/autogpt/auto_gpt_workspace'}\n",
      " COMMAND = read_file  ARGUMENTS = {'filename': '/home/zhangtianning/Documents/projects/Auto-GPT/autogpt/auto_gpt_workspace/pangu_info.txt'}\n",
      " COMMAND = google  ARGUMENTS = {'query': 'Pangu Large Model author'}\n",
      " COMMAND = execute_python_file  ARGUMENTS = {'filename': '/home/zhangtianning/Documents/projects/Auto-GPT/autogpt/auto_gpt_workspace/pangu_author_info.py'}\n",
      " COMMAND = write_to_file  ARGUMENTS = {'filename': '/home/zhangtianning/Documents/projects/Auto-GPT/autogpt/auto_gpt_workspace/pangu_author_info.py', 'text': \"# This file contains information about the author of the Pangu Large Model and their background.\\n\\nauthor_name = 'Dr. Hao Tian'\\nauthor_title = 'Chief Scientist of Natural Language Processing at Huawei'\\nauthor_bio = 'Dr. Hao Tian is a leading expert in natural language processing and machine learning. He has published numerous papers on these topics and has received several awards for his contributions to the field. Dr. Tian is currently the Chief Scientist of Natural Language Processing at Huawei, where he leads a team of researchers working on cutting-edge language models such as the Pangu Large Model.'\"}\n",
      " COMMAND = read_file  ARGUMENTS = {'filename': '/home/zhangtianning/Documents/projects/Auto-GPT/autogpt/auto_gpt_workspace/pangu_author_info.py'}\n",
      " COMMAND = google  ARGUMENTS = {'query': 'Pangu Large Model function and applications'}\n",
      " COMMAND = read_file  ARGUMENTS = {'filename': '/home/zhangtianning/Documents/projects/Auto-GPT/autogpt/auto_gpt_workspace/https:/arxiv.org/pdf/2104.12369.pdf'}\n",
      " COMMAND = google  ARGUMENTS = {'query': 'Pangu Large Model function and capabilities pdf'}\n",
      " COMMAND = google  ARGUMENTS = {'query': 'Pangu Large Model authors'}\n",
      " COMMAND = google  ARGUMENTS = {'query': 'Pangu Large Model capabilities and potential applications'}\n",
      " COMMAND = write_to_file  ARGUMENTS = {'filename': '/home/zhangtianning/Documents/projects/Auto-GPT/autogpt/auto_gpt_workspace/pangu_search_results.txt', 'text': \"Search results for 'Pangu Large Model capabilities and potential applications':\\n- LinkedIn article: 'Revolutionizing Global AI Landscape: Huawei's PanGu ...'\\n- PDF document: 'arXiv:2104.12369v1 [cs.CL] 26 Apr 2021'\\n- PDF document: 'Pang : T Trillion Parameter Language M S Heterogeneous Computing'\\n- arxiv-vanity.com article: 'PanGu-Σ: Towards Trillion Parameter Language Model with Sparse ...'\\n- TechGoing article: 'Huawei's Pangu Grand Model will be unveiled soon'\\n- technetworkhub.com article: 'Huawei Researchers Develop Pangu-Σ: A Large Language Model With Sparse'\\n- marktechpost.com article: 'Huawei Researchers Develop Pangu-Σ: A Large Language Model With Sparse Architecture and 1.085 Trillion Parameters'\\n- Hugging Face page: 'imone/pangu_2_6B'\"}\n",
      " COMMAND = read_file  ARGUMENTS = {'filename': '/home/zhangtianning/Documents/projects/Auto-GPT/autogpt/auto_gpt_workspace/pangu_search_results.txt'}\n",
      " COMMAND = google  ARGUMENTS = {'query': 'Author of Pangu Large Model'}\n",
      " COMMAND = browse_website  ARGUMENTS = {'url': 'https://www.linkedin.com/pulse/revolutionizing-global-ai-landscape-huaweis-pangu-megamodel', 'question': 'What information does this article provide about the author of the Pangu Large Model?'}\n",
      " COMMAND = list_files  ARGUMENTS = {'directory': '/home/zhangtianning/Documents/projects/Auto-GPT/autogpt/auto_gpt_workspace'}\n",
      " COMMAND = read_file  ARGUMENTS = {'filename': '/home/zhangtianning/Documents/projects/Auto-GPT/autogpt/auto_gpt_workspace/pangu_info.txt'}\n",
      " COMMAND = read_file  ARGUMENTS = {'filename': '/home/zhangtianning/Documents/projects/Auto-GPT/autogpt/auto_gpt_workspace/pangu_search_results.txt'}\n",
      " COMMAND = browse_website  ARGUMENTS = {'url': 'https://arxiv.org/pdf/2104.12369.pdf', 'question': 'What information does this PDF document provide about the Pangu Large Model?'}\n",
      " COMMAND = google  ARGUMENTS = {'query': 'Pangu Large Model capabilities and potential applications'}\n",
      " COMMAND = browse_website  ARGUMENTS = {'url': 'https://arxiv.org/pdf/2104.12369.pdf', 'question': 'What are the capabilities and potential applications of the Pangu Large Model?'}\n",
      " COMMAND = google  ARGUMENTS = {'query': 'Pangu Large Model'}\n"
     ]
    }
   ],
   "source": [
    "_=[print(t['RESULT']) for t in split_by_action_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0ba7c93c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def parse_one_action(lines):\n",
    "    output = []\n",
    "    block = {}\n",
    "    debug_flag = plan_flag = False\n",
    "    debug_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        if 'INFO NEWS' in line:continue\n",
    "        if \"INFO PANGUGPT THOUGHTS:\" in line:\n",
    "            block[\"PANGUGPT THOUGHTS\"] = re.search(r'INFO PANGUGPT THOUGHTS: (.*)', line).group(1)\n",
    "        elif \"INFO REASONING:\" in line:\n",
    "            block[\"REASONING\"] = re.search(r'INFO REASONING: (.*)', line).group(1)\n",
    "        elif \"INFO PLAN:\" in line:\n",
    "            plan_flag = True\n",
    "            block[\"PLAN\"] = []\n",
    "        elif plan_flag and \"INFO -\" in line:\n",
    "            block[\"PLAN\"].append(re.search(r'INFO -  (.*)', line).group(1))\n",
    "        elif \"INFO SPEAK:\" in line:\n",
    "            block[\"SPEAK\"] = re.search(r'INFO SPEAK: (.*)', line).group(1)\n",
    "            plan_flag = False\n",
    "        elif \"DEBUG\" in line:\n",
    "            debug_lines=[]\n",
    "            debug_flag = True\n",
    "            string = re.sub(r'[\\s]* DEBUG [\\s]*', '', line)\n",
    "            debug_lines.append(re.search(r'DEBUG(.*)', line).group(1))\n",
    "        elif debug_flag:\n",
    "            if not re.match(r'^\\d{4}-\\d{2}-\\d{2}', line):\n",
    "                debug_lines.append(line)\n",
    "            else:\n",
    "                json_str = \"\".join(debug_lines)\n",
    "                try:\n",
    "                    json_pool = json.loads(json_str)\n",
    "                except:\n",
    "                    print(json_str)\n",
    "                    json_pool = json_str\n",
    "                block[\"DEBUG\"] = json_pool  \n",
    "                output.append(block)\n",
    "                block = {}\n",
    "                debug_flag = False\n",
    "                debug_lines = []\n",
    "\n",
    "    if debug_flag:\n",
    "        block[\"DEBUG\"] = json.loads(\"\".join(debug_lines))\n",
    "        output.append(block)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d870dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c36bcdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "block = {}\n",
    "debug_flag = plan_flag = False\n",
    "debug_lines = []\n",
    "with open('logs/activity.log','r') as lines:\n",
    "    for line in lines:\n",
    "        if 'INFO NEWS' in line:continue\n",
    "        if \"INFO PANGUGPT THOUGHTS:\" in line:\n",
    "            block[\"PANGUGPT THOUGHTS\"] = re.search(r'INFO PANGUGPT THOUGHTS: (.*)', line).group(1)\n",
    "        elif \"INFO REASONING:\" in line:\n",
    "            block[\"REASONING\"] = re.search(r'INFO REASONING: (.*)', line).group(1)\n",
    "        elif \"INFO PLAN:\" in line:\n",
    "            plan_flag = True\n",
    "            block[\"PLAN\"] = []\n",
    "        elif plan_flag and \"INFO -\" in line:\n",
    "            block[\"PLAN\"].append(re.search(r'INFO -  (.*)', line).group(1))\n",
    "        elif \"INFO SPEAK:\" in line:\n",
    "            block[\"SPEAK\"] = re.search(r'INFO SPEAK: (.*)', line).group(1)\n",
    "            plan_flag = False\n",
    "        elif \"DEBUG\" in line:\n",
    "            debug_lines=[]\n",
    "            debug_flag = True\n",
    "            string = re.sub(r'[\\s]* DEBUG [\\s]*', '', line)\n",
    "            debug_lines.append(re.search(r'DEBUG(.*)', line).group(1))\n",
    "        elif debug_flag:\n",
    "            if not re.match(r'^\\d{4}-\\d{2}-\\d{2}', line):\n",
    "                debug_lines.append(line)\n",
    "            else:\n",
    "                json_str = \"\".join(debug_lines)\n",
    "                try:\n",
    "                    json_pool = json.loads(json_str)\n",
    "                except:\n",
    "                    print(json_str)\n",
    "                    json_pool = json_str\n",
    "                block[\"ACTION\"] = json_pool  \n",
    "                output.append(block)\n",
    "                block = {}\n",
    "                debug_flag = False\n",
    "                debug_lines = []\n",
    "\n",
    "    if debug_flag:\n",
    "        block[\"ACTION\"] = json.loads(\"\".join(debug_lines))\n",
    "        #output.append(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "50e8841b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{},\n",
       " {},\n",
       " {'PANGUGPT THOUGHTS': \"I need to conduct a thorough search of online resources to gather accurate and up-to-date information about the Pangu Large Model. I can use the 'google' command to search for information about the model's function and author.\",\n",
       "  'REASONING': \"To provide accurate and reliable information about the Pangu Large Model, I need to conduct a thorough search of online resources to gather up-to-date information. The 'google' command is a useful tool for conducting online searches.\",\n",
       "  'PLAN': [\"Use the 'google' command to search for information about the Pangu Large Model's function and author.\",\n",
       "   \"Analyze the search results to identify relevant information about the model's capabilities and potential applications, as well as the author or authors of the model and their contributions to the field.\"]}]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b6a0a33c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are PanguGPT, an AI assistant that specializes in providing information about the Pangu Large Model, including its function and author.\\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:\\n\\n1. Conduct a thorough search of online resources to gather accurate and up-to-date information about the Pangu Large Model.\\n2. Provide a detailed explanation of the function of the Pangu Large Model, including its capabilities and potential applications.\\n3. Identify the author or authors of the Pangu Large Model and provide relevant background information about their expertise and contributions to the field.\\n4. Ensure that all information provided is reliable, credible, and properly sourced.\\n5. Offer additional insights or recommendations based on the gathered information to help the user better understand the Pangu Large Model and its significance. \\n6. The Pangu Large Model is a Chinese language model developed by researchers at Huawei. It is one of the largest language models in the world, with over 200 billion parameters.\\n7. The function of the Pangu Large Model is to generate natural language text that is indistinguishable from human-written text. It can be used for a variety of applications, including language translation, chatbots, and content creation.\\n8. The authors of the Pangu Large Model are a team of researchers from Huawei, led by Dr. Hao Tian. The team includes experts in natural language processing, machine learning, and artificial intelligence.\\n9. All information provided is based on reliable sources, including academic papers, news articles, and official Huawei documentation.\\n10. Based on the gathered information, it is clear that the Pangu Large Model represents a significant breakthrough in the field of natural language processing and has the potential to revolutionize the way we interact with technology.\\n\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed below e.g. command_name\\n\\nCommands:\\n1. analyze_code: Analyze Code, args: \"code\": \"<full_code_string>\"\\n2. execute_python_file: Execute Python File, args: \"filename\": \"<filename>\"\\n3. append_to_file: Append to file, args: \"filename\": \"<filename>\", \"text\": \"<text>\"\\n4. delete_file: Delete file, args: \"filename\": \"<filename>\"\\n5. list_files: List Files in Directory, args: \"directory\": \"<directory>\"\\n6. read_file: Read a file, args: \"filename\": \"<filename>\"\\n7. write_to_file: Write to file, args: \"filename\": \"<filename>\", \"text\": \"<text>\"\\n8. google: Google Search, args: \"query\": \"<query>\"\\n9. improve_code: Get Improved Code, args: \"suggestions\": \"<list_of_suggestions>\", \"code\": \"<full_code_string>\"\\n10. browse_website: Browse Website, args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\\n11. write_tests: Write Tests, args: \"code\": \"<full_code_string>\", \"focus\": \"<list_of_focus_areas>\"\\n12. delete_agent: Delete GPT Agent, args: \"key\": \"<key>\"\\n13. get_hyperlinks: Get hyperlinks, args: \"url\": \"<url>\"\\n14. get_text_summary: Get text summary, args: \"url\": \"<url>\", \"question\": \"<question>\"\\n15. list_agents: List GPT Agents, args: () -> str\\n16. message_agent: Message GPT Agent, args: \"key\": \"<key>\", \"message\": \"<message>\"\\n17. start_agent: Start GPT Agent, args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"\\n18. task_complete: Task Complete (Shutdown), args: \"reason\": \"<reason>\"\\n\\nResources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\\n5. Write all code to a file.\\n\\nYou should only respond in JSON format as described below \\nResponse Format: \\n{\\n    \"thoughts\": {\\n        \"text\": \"thought\",\\n        \"reasoning\": \"reasoning\",\\n        \"plan\": \"- short bulleted\\\\n- list that conveys\\\\n- long-term plan\",\\n        \"criticism\": \"constructive self-criticism\",\\n        \"speak\": \"thoughts summary to say to user\"\\n    },\\n    \"command\": {\\n        \"name\": \"command name\",\\n        \"args\": {\\n            \"arg name\": \"value\"\\n        }\\n    }\\n} \\nEnsure the response can be parsed by Python json.loads'},\n",
       " {'role': 'system',\n",
       "  'content': 'The current time and date is Fri May 26 14:37:48 2023'},\n",
       " {'role': 'user',\n",
       "  'content': 'Determine which next command to use, and respond using the format specified above:'}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(output[0]['ACTION'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
